### IMPORTANT, THIS IMAGE CAN ONLY BE RUN IN LINUX DOCKER
### You will run into a segfault in mac
FROM python:3.11.6-slim-bookworm as base

# Install poetry
RUN pip install pipx
RUN python3 -m pipx ensurepath
RUN pipx install poetry
ENV PATH="/root/.local/bin:$PATH"
ENV PATH=".venv/bin/:$PATH"

# Dependencies to build llama-cpp
RUN apt update && apt install -y \
  libopenblas-dev\
  ninja-build\
  build-essential\
  pkg-config\
  wget

# https://python-poetry.org/docs/configuration/#virtualenvsin-project
ENV POETRY_VIRTUALENVS_IN_PROJECT=true

FROM base as dependencies
WORKDIR /home/worker/app
COPY pyproject.toml poetry.lock ./

# TODO check if it's possible to embed with RAM and huggingface embedder?
# TODO remove embeddings-huggingface if not gonna use (gives error for now)
RUN poetry install --extras "ui llms-ollama vector-stores-qdrant embeddings-ollama"

# Optional install(s):
# RUN pip3 install docx2txt

FROM base as app
WORKDIR /home/worker/app

ENV PYTHONUNBUFFERED=1
ENV PORT=8080
EXPOSE 8080

# Prepare a non-root user
RUN adduser worker

# Special dirs
RUN mkdir -p .config/matplotlib; chown worker .config/matplotlib
ENV MPLCONFIGDIR="/home/worker/app/.config/matplotlib"
RUN mkdir -p .cache/huggingface; chown worker .cache/huggingface
ENV HF_HOME="/home/worker/app/.cache/huggingface"

RUN mkdir local_data
RUN mkdir -p models/cache
COPY --chown=worker --from=dependencies /home/worker/app/.venv/ .venv
COPY --chown=worker private_gpt/ private_gpt
COPY --chown=worker *.yaml *.md ./
COPY --chown=worker scripts/ scripts
COPY --chown=worker tiktoken_cache/ tiktoken_cache

# NOTE: no idea why fern was copied; fastapi /docs page is still available without
# COPY --chown=worker fern/ fern

ENV PYTHONPATH="$PYTHONPATH:/private_gpt/"

USER worker
ENTRYPOINT .venv/bin/python -m private_gpt
