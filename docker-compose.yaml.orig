services:
  private-gpt:
    build:
<<<<<<< HEAD
      dockerfile: Dockerfile.local
#      dockerfile: Dockerfile.gpu
=======
      dockerfile: Dockerfile.external
>>>>>>> privategpt/main
    volumes:
      - ./local_data/:/home/worker/app/local_data
    ports:
      - 8001:8080
    environment:
      PORT: 8080
      PGPT_PROFILES: docker
<<<<<<< HEAD
      PGPT_MODE: llamacpp
#    deploy:
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: 1
#              capabilities: [ gpu ]
=======
      PGPT_MODE: ollama
  ollama:
    image: ollama/ollama:latest
    volumes:
      - ./models:/root/.ollama
>>>>>>> privategpt/main
